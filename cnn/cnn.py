# -*- coding: utf-8 -*-
"""Шефер Эрика Александровна CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K3FavY5ZZciMJr5U8n8rKS6RRmbLbLUA
"""

import torch
import random
import numpy as np
from tqdm.auto import tqdm
from sklearn.metrics import confusion_matrix
import seaborn
import pandas as pd
import matplotlib.pyplot as plt

import torchvision.datasets
MNIST_train = torchvision.datasets.FashionMNIST('./', download=True, train=True)
MNIST_test = torchvision.datasets.FashionMNIST('./', download=True, train=False)

X_train = MNIST_train.data
y_train = MNIST_train.targets
X_test = MNIST_test.data
y_test = MNIST_test.targets

X_train = X_train.float()
X_test = X_test.float()

X_train = X_train.unsqueeze(1).float()
X_test = X_test.unsqueeze(1).float()

class LeNet5(torch.nn.Module):
    def __init__(self):
        super(LeNet5, self).__init__()
        
        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, padding=2)
        self.act1  = torch.nn.GELU()
        self.pool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)
       
        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, padding=0)
        self.act2  = torch.nn.GELU()
        self.pool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)
        
        self.fc1   = torch.nn.Linear(5 * 5 * 32, 120)
        self.act3  = torch.nn.GELU()

        self.fc2   = torch.nn.Linear(120, 80)
        self.act4  = torch.nn.GELU()
        
        self.fc3   = torch.nn.Linear(80, 10)
    
    def forward(self, x):
        
        x = self.conv1(x)
        x = self.act1(x)
        x = self.pool1(x)
        
        x = self.conv2(x)
        x = self.act2(x)
        x = self.pool2(x)
        
        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))

        x = self.fc1(x)
        x = self.act3(x)

        x = self.fc2(x)
        x = self.act4(x)

        x = self.fc3(x)
        
        return x

datasets = {}
datasets['train'] = torch.utils.data.TensorDataset(X_train, y_train)
datasets['valid'] = torch.utils.data.TensorDataset(X_test, y_test)

dataloaders = {
    mode: torch.utils.data.DataLoader(
      dataset, 
      batch_size=128, 
      shuffle=(mode=='train'), 
      num_workers=4, 
      drop_last=(mode=='train'), 
      pin_memory=True
    ) for mode, dataset in datasets.items()
}

def imshow(tensor, ax):
    img = tensor.numpy().transpose(1, 2, 0)
    img = np.repeat(img, 3, axis=2)
    img = np.clip(img, 0, 1)
    ax.imshow(img)

def train_epoch(model, dataloader, optimizer, loss_fun, device):
    for (data, target) in tqdm(dataloader, leave=False):
        data = data.to(device)
        target = target.to(device)

        optimizer.zero_grad()

        out = model(data)
        loss = loss_fun(out, target)
        loss.backward()
        optimizer.step()

def evaluate(model, dataloader, device):
    outs = []
    with torch.no_grad():
        for (data, target) in tqdm(dataloader, leave=False):
            data = data.to(device)
            target = target.to(device)

            out = model(data)
            outs.append(out.cpu().numpy())
    return np.concatenate(outs)

def show_confusion_matrix(predictions, targets):
    predictions = np.argmax(predictions, axis=1)
    matrix = confusion_matrix(targets, predictions)
    df_cm = pd.DataFrame(matrix)
    plt.figure(figsize = (10,7))
    seaborn.heatmap(df_cm, annot=True)
    plt.title("Accuracy: " + str((predictions==np.array(targets)).mean()))
    plt.show()

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
lenet5 = LeNet5().to(device)
loss = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(lenet5.parameters(), lr=1.0e-3)

for epoch in tqdm(range(30)):
    train_epoch(lenet5, dataloaders['train'], optimizer, loss, device)
    if epoch % 5 == 0:
        predictions = evaluate(lenet5, dataloaders['valid'], device)
        show_confusion_matrix(predictions, y_test)

predictions = evaluate(lenet5, dataloaders['valid'], device)
max_value = [[(0, 0)] * 10 for i in range(10)]
for sample in range(len(predictions)):
    target = y_test[sample]
    for pred in range(10):
        max_value[target][pred] = max(max_value[target][pred], (predictions[sample][pred], sample))

fig, axs = plt.subplots(10, 10, figsize=(15, 15))
for i in range(10):
    for j in range(10):
        if max_value[i][j][0] == 0: continue
        ind = max_value[i][j][1]
        imshow(datasets['valid'][ind][0], axs[i][j])

